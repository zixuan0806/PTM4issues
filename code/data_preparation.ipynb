{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "011a2e2a-0505-4cd0-af48-6ec3787aff33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dbdc070-7e96-4959-a409-66f573352ff0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('./my_data/train/Real-Time-Voice-Cloning.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1931c4ba-e7f6-4f69-9721-534c3b738d84",
   "metadata": {},
   "source": [
    "### Add Length of title and description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5ec2e64-1c1d-41d0-91ed-f238b38549f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullname</th>\n",
       "      <th>number</th>\n",
       "      <th>html_url</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iperov/DeepFaceLab</td>\n",
       "      <td>1</td>\n",
       "      <td>https://github.com/iperov/DeepFaceLab/issues/1</td>\n",
       "      <td>`Error: Sorry, this model works only on 2GB+ G...</td>\n",
       "      <td>## Expected behavior_x000D_\\nStart training._x...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fullname  number                                        html_url  \\\n",
       "0  iperov/DeepFaceLab       1  https://github.com/iperov/DeepFaceLab/issues/1   \n",
       "\n",
       "                                               title  \\\n",
       "0  `Error: Sorry, this model works only on 2GB+ G...   \n",
       "\n",
       "                                         description labels  \n",
       "0  ## Expected behavior_x000D_\\nStart training._x...  other  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd77ed3-cf6e-4bc5-8d48-6bd0ef54841a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _strlen(sentence):\n",
    "    import re\n",
    "    zhmodel = re.compile(u'[\\u4e00-\\u9fa5]')  #检查中文\n",
    "    contents = str(sentence)\n",
    "    match = zhmodel.search(contents)\n",
    "    if match:\n",
    "        return -1\n",
    "    else:\n",
    "        return len(str(sentence).strip().split(' '))\n",
    "\n",
    "title_lens, body_lens = df['title'].apply(_strlen), df['description'].apply(_strlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4f3701f-47f5-4e4a-bc8a-6860f21ee60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns\n",
    "df.insert(loc=df.columns.get_loc(\"title\") + 1, column='title_lens', value=title_lens)\n",
    "df.insert(loc=df.columns.get_loc(\"description\") + 1, column='description_lens', value=body_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4c02665-4b6d-458a-bffc-2ee713917eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullname</th>\n",
       "      <th>number</th>\n",
       "      <th>html_url</th>\n",
       "      <th>title</th>\n",
       "      <th>title_lens</th>\n",
       "      <th>description</th>\n",
       "      <th>description_lens</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iperov/DeepFaceLab</td>\n",
       "      <td>1</td>\n",
       "      <td>https://github.com/iperov/DeepFaceLab/issues/1</td>\n",
       "      <td>`Error: Sorry, this model works only on 2GB+ G...</td>\n",
       "      <td>15</td>\n",
       "      <td>## Expected behavior_x000D_\\nStart training._x...</td>\n",
       "      <td>375</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fullname  number                                        html_url  \\\n",
       "0  iperov/DeepFaceLab       1  https://github.com/iperov/DeepFaceLab/issues/1   \n",
       "\n",
       "                                               title  title_lens  \\\n",
       "0  `Error: Sorry, this model works only on 2GB+ G...          15   \n",
       "\n",
       "                                         description  description_lens labels  \n",
       "0  ## Expected behavior_x000D_\\nStart training._x...               375  other  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366f778f-3d1a-43d8-80de-43fd06e0ce55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7815b19-f479-48d0-ae11-25be9db92434",
   "metadata": {},
   "source": [
    "### Remove nan Label and short title with no description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3872e9c-7526-4fee-b010-05c04b4433bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['other', 'Low efficiency and Effectiveness', 'deployment', 'Error',\n",
       "       'tensor&inputs'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['labels'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b1e5d64-aa13-465e-be54-591ea2cc96fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullname</th>\n",
       "      <th>number</th>\n",
       "      <th>html_url</th>\n",
       "      <th>title</th>\n",
       "      <th>title_lens</th>\n",
       "      <th>description</th>\n",
       "      <th>description_lens</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [fullname, number, html_url, title, title_lens, description, description_lens, labels]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contain_na = df[df['labels'].isnull()]\n",
    "contain_na.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ede29a6-0509-497b-8489-dd8d582a8959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before:716, after:716\n"
     ]
    }
   ],
   "source": [
    "len_before = len(df)\n",
    "df.dropna(subset = ['labels'], inplace=True)\n",
    "len_after = len(df)\n",
    "print(f'before:{len_before}, after:{len_after}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea49335a-5cbe-4ca4-ad85-795173434792",
   "metadata": {},
   "outputs": [],
   "source": [
    "contain_chinese_characters = df[((df.title_lens == -1) & (df.description_lens == -1))]\n",
    "df = df.drop(contain_chinese_characters.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48dcd06b-399a-4bf8-950e-7f7a16e2cf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_nan = df[((df.title_lens == 1) & (df.description.isnull()))]\n",
    "df = df.drop(body_nan.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d14652-cccc-4e3c-9d75-02b6d1f4b020",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbbdaa67-0e94-4ad9-ae16-378dfea2f306",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['title_lens', 'description_lens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3defdda-051a-4621-bd61-b0b064d223bd",
   "metadata": {},
   "source": [
    "# save the new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f1fdec7-2b0e-42c7-9197-3e1f09afa907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iperov_DeepFaceLab'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = '_'.join(df['fullname'][0].split('/'))\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64405daa-72d7-4e55-859d-ba4cf16ceafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join('./my_data', name)):\n",
    "    os.mkdir(os.path.join('./my_data', name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffdc6266-18b5-4390-b103-6d0c8caf480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(f'{name}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8d975e0-a355-4b3a-af2d-ee7bd09790f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "result = df[['title', 'description', 'labels']].to_json(orient=\"records\")\n",
    "parsed = json.loads(result)\n",
    "\n",
    "with open(f'{name}.txt', 'w') as f:\n",
    "    json.dump(parsed, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5861269d-d29c-4ce1-942b-e7280cd59989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'setUpfailed', 'description': '![default](https://user-images.githubusercontent.com/28338863/53715027-7e309480-3e8b-11e9-8d5b-aebb44e63f9e.png)\\r\\n\\r\\ndear editor,what does these mean?', 'labels': 'other'}\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "with open('deepfakes_faceswap.txt', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for obj in data:\n",
    "    print(obj)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86894a34-5dd3-4553-a2e4-895b3163d061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95766f52-c15c-40fc-a9e7-8f2f17c2250f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3dd6cbf-0e24-4b5c-9a17-c3959414d52d",
   "metadata": {},
   "source": [
    "## Combine the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f491ada-a48c-4f2f-878c-5717be875f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "defff7f8-1883-4ca2-95e6-1f7db4ee3ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _strlen(sentence):\n",
    "    import re\n",
    "    zhmodel = re.compile(u'[\\u4e00-\\u9fa5]')  #检查中文\n",
    "    contents = str(sentence)\n",
    "    match = zhmodel.search(contents)\n",
    "    if match:\n",
    "        return -1\n",
    "    else:\n",
    "        return len(str(sentence).strip().split(' '))\n",
    "\n",
    "def concatenate_df_and_save(dfs):\n",
    "    df = pd.concat(dfs)\n",
    "    dir_name = os.path.join('./my_data/train', 'concat')\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.mkdir(dir_name)\n",
    "    \n",
    "    out_path = os.path.join(dir_name, 'concat.txt')\n",
    "    result = df[['title', 'description', 'labels']].to_json(orient=\"records\")\n",
    "    parsed = json.loads(result)\n",
    "    with open(out_path, 'w') as f:\n",
    "        json.dump(parsed, f)\n",
    "\n",
    "def save_df(df, filename):\n",
    "    dir_name = os.path.join('./my_data/train', filename)\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.mkdir(dir_name)\n",
    "    \n",
    "    out_path = os.path.join(dir_name, filename + '.txt')\n",
    "    result = df[['title', 'description', 'labels']].to_json(orient=\"records\")\n",
    "    parsed = json.loads(result)\n",
    "    with open(out_path, 'w') as f:\n",
    "        json.dump(parsed, f)\n",
    "    \n",
    "def preprocess(file):\n",
    "    df = pd.read_excel(file)\n",
    "    # add title and description length\n",
    "    title_lens, description_lens = df['title'].apply(_strlen), df['description'].apply(_strlen)\n",
    "\n",
    "    df.insert(loc=df.columns.get_loc(\"title\") + 1, column='title_lens', value=title_lens)\n",
    "    df.insert(loc=df.columns.get_loc(\"description\") + 1, column='description_lens', value=description_lens)\n",
    "    \n",
    "    name = '_'.join(df['fullname'][0].split('/'))\n",
    "    print(f'before drop, the length of {name} is:{len(df)}')\n",
    "    \n",
    "    # drop the nan\n",
    "    df.dropna(subset = ['title', 'description', 'labels'], inplace=True)\n",
    "    \n",
    "    # drop the chinese issues\n",
    "    contain_chinese_characters = df[((df.title_lens == -1) & (df.description_lens == -1))]\n",
    "    df.drop(contain_chinese_characters.index, inplace=True)\n",
    "    \n",
    "    print(f'after drop, the length of {name} is:{len(df)}')\n",
    "\n",
    "    # whether or not to convert erery xlxs file to json file\n",
    "    \n",
    "    # name = '_'.join(df['fullname'][0].split('/'))\n",
    "    # dir_name = os.path.join('./my_data', name)\n",
    "    # if not os.path.exists(dir_name):\n",
    "    #     os.mkdir(dir_name)\n",
    "    \n",
    "    # out_path = os.path.join(dir_name, f'{name}.txt')\n",
    "    # result = df[['title', 'description', 'labels']].to_json(orient=\"records\")\n",
    "    # parsed = json.loads(result)\n",
    "\n",
    "    # with open(out_path, 'w') as f:\n",
    "    #     json.dump(parsed, f)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70292c59",
   "metadata": {},
   "source": [
    "### Concat train file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b097de64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs = []\n",
    "# dfs.append(preprocess('my_data/train/pytorch-CycleGAN-and-pix2pix_TRAIN_Aug.xlsx'))\n",
    "# dfs.append(preprocess('my_data/train/Real-Time-Voice-Cloning_TRAIN_Aug.xlsx'))\n",
    "# dfs.append(preprocess('my_data/train/EasyOCR_TRAIN_Aug.xlsx'))\n",
    "# dfs.append(preprocess('my_data/train/recommenders1_TRAIN_Aug.xlsx')) \n",
    "# # dfs.append(preprocess('my_data/train/streamlit1_TRAIN_Aug.xlsx'))\n",
    "# concatenate_df_and_save(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e4e5486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before drop, the length of deezer_spleeter is:1968\n",
      "after drop, the length of deezer_spleeter is:1920\n"
     ]
    }
   ],
   "source": [
    "#save_df(preprocess('my_data/train/TTS3_TRAIN_Aug.xlsx'), 'TTS3_TRAIN_Aug')\n",
    "#save_df(preprocess('my_data/train/Real-Time-Voice-Cloning_TRAIN_Aug.xlsx'), 'Real-Time-Voice-Cloning_TRAIN_Aug')\n",
    "#save_df(preprocess('my_data/train/EasyOCR_TRAIN_Aug.xlsx'), 'EasyOCR_TRAIN_Aug')\n",
    "#save_df(preprocess('my_data/train/recommenders3_TRAIN_Aug.xlsx'), 'recommenders3_TRAIN_Aug') \n",
    "#save_df(preprocess('my_data/train/streamlit1_TRAIN_Aug.xlsx'), 'streamlit1_TRAIN_Aug')\n",
    "#save_df(preprocess('my_data/train/faceswap_TRAIN_Aug.xlsx'), 'faceswap_TRAIN_Aug')\n",
    "#save_df(preprocess('my_data/train/deepfacelab1_TRAIN_Aug.xlsx'), 'deepfacelab1_TRAIN_Aug')\n",
    "#save_df(preprocess('my_data/train/openpose0_TRAIN_Aug.xlsx'), 'openpose0_TRAIN_Aug')\n",
    "save_df(preprocess('my_data/train/contact2_TRAIN_Aug.xlsx'), 'contact2_TRAIN_Aug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fff039e1-e625-4ea9-bcc8-123ee581d694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./my_data/train\\deepfacelab.xlsx\n",
      "./my_data/train\\EasyOCR.xlsx\n",
      "./my_data/train\\EasyOCR_TRAIN_Aug.xlsx\n",
      "./my_data/train\\faceswap.xlsx\n",
      "./my_data/train\\faceswap_TRAIN_Aug.xlsx\n",
      "./my_data/train\\pytorch-CycleGAN-and-pix2pix.xlsx\n",
      "./my_data/train\\pytorch-CycleGAN-and-pix2pix_TRAIN_Aug.xlsx\n",
      "./my_data/train\\Real-Time-Voice-Cloning.xlsx\n",
      "./my_data/train\\Real-Time-Voice-Cloning_TRAIN_Aug.xlsx\n",
      "./my_data/train\\recommenders.xlsx\n",
      "./my_data/train\\recommenders1.xlsx\n",
      "./my_data/train\\recommenders1_TRAIN_Aug.xlsx\n",
      "./my_data/train\\recommenders_TRAIN_Aug.xlsx\n",
      "./my_data/train\\spleeter.xlsx\n",
      "./my_data/train\\streamlit.xlsx\n",
      "./my_data/train\\streamlit1.xlsx\n",
      "./my_data/train\\streamlit1_TRAIN_Aug.xlsx\n",
      "./my_data/train\\TTS.xlsx\n",
      "before drop, the length of iperov_DeepFaceLab is:716\n",
      "after drop, the length of iperov_DeepFaceLab is:701\n",
      "before drop, the length of JaidedAI_EasyOCR is:544\n",
      "after drop, the length of JaidedAI_EasyOCR is:516\n",
      "before drop, the length of JaidedAI_EasyOCR is:615\n",
      "after drop, the length of JaidedAI_EasyOCR is:587\n",
      "before drop, the length of deepfakes_faceswap is:705\n",
      "after drop, the length of deepfakes_faceswap is:688\n",
      "before drop, the length of deepfakes_faceswap is:772\n",
      "after drop, the length of deepfakes_faceswap is:755\n",
      "before drop, the length of junyanz_pytorch-CycleGAN-and-pix2pix is:917\n",
      "after drop, the length of junyanz_pytorch-CycleGAN-and-pix2pix is:875\n",
      "before drop, the length of junyanz_pytorch-CycleGAN-and-pix2pix is:1014\n",
      "after drop, the length of junyanz_pytorch-CycleGAN-and-pix2pix is:972\n",
      "before drop, the length of CorentinJ_Real-Time-Voice-Cloning is:842\n",
      "after drop, the length of CorentinJ_Real-Time-Voice-Cloning is:808\n",
      "before drop, the length of CorentinJ_Real-Time-Voice-Cloning is:1018\n",
      "after drop, the length of CorentinJ_Real-Time-Voice-Cloning is:984\n",
      "before drop, the length of microsoft_recommenders is:486\n",
      "after drop, the length of microsoft_recommenders is:468\n",
      "before drop, the length of microsoft_recommenders is:486\n",
      "after drop, the length of microsoft_recommenders is:468\n",
      "before drop, the length of microsoft_recommenders is:581\n",
      "after drop, the length of microsoft_recommenders is:563\n",
      "before drop, the length of microsoft_recommenders is:576\n",
      "after drop, the length of microsoft_recommenders is:558\n",
      "before drop, the length of deezer_spleeter is:500\n",
      "after drop, the length of deezer_spleeter is:495\n",
      "before drop, the length of streamlit_streamlit is:1623\n",
      "after drop, the length of streamlit_streamlit is:1585\n",
      "before drop, the length of streamlit_streamlit is:1623\n",
      "after drop, the length of streamlit_streamlit is:1585\n",
      "before drop, the length of streamlit_streamlit is:1982\n",
      "after drop, the length of streamlit_streamlit is:1943\n",
      "before drop, the length of mozilla_TTS is:506\n",
      "after drop, the length of mozilla_TTS is:478\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob('./my_data/train/*.xlsx')\n",
    "for f in files:\n",
    "    print(f)\n",
    "\n",
    "dfs = []\n",
    "for f in files:\n",
    "    dfs.append(preprocess(f))\n",
    "concatenate_df_and_save(dfs)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d611377",
   "metadata": {},
   "source": [
    "## process one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a58b8a12-cf35-4f51-b19d-1bb227b48aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before drop, the length of mozilla_TTS is:506\n",
      "after drop, the length of mozilla_TTS is:478\n"
     ]
    }
   ],
   "source": [
    "test_file = './my_data/test/TTS.xlsx'\n",
    "def save_test_to_txt(file):\n",
    "    df = preprocess(file)\n",
    "    file_name = file.split('/')[-1].split('.')[0]\n",
    "    dir_name = os.path.join('./my_data/test', file_name)\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.mkdir(dir_name)\n",
    "    \n",
    "    out_path = os.path.join(dir_name, f'{file_name}.txt')\n",
    "    result = df[['title', 'description', 'labels']].to_json(orient=\"records\")\n",
    "    parsed = json.loads(result)\n",
    "    with open(out_path, 'w') as f:\n",
    "        json.dump(parsed, f)\n",
    "\n",
    "save_test_to_txt(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7bb83c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31561f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cc42da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c520c937fa0229155174b690de588d25c33cbfee0f5b82be1870097f0ee1af71"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
